{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cb8b7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
      "pip install 'aif360[inFairness]'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import resample\n",
    "from aif360.datasets import CompasDataset\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from fairlearn.metrics import (\n",
    "    demographic_parity_difference,\n",
    "    equalized_odds_difference,\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebdec93",
   "metadata": {},
   "source": [
    "#### STEP 1: Load COMPAS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9907d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOError: [Errno 2] No such file or directory: '/home/sidnaik04/Documents/BiasBuster/code_demo/venv/lib/python3.12/site-packages/aif360/datasets/../data/raw/compas/compas-scores-two-years.csv'\n",
      "To use this class, please download the following file:\n",
      "\n",
      "\thttps://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv\n",
      "\n",
      "and place it, as-is, in the folder:\n",
      "\n",
      "\t/home/sidnaik04/Documents/BiasBuster/code_demo/venv/lib/python3.12/site-packages/aif360/data/raw/compas\n",
      "\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 1\n"
     ]
    }
   ],
   "source": [
    "compas_data = CompasDataset()\n",
    "df = compas_data.convert_to_dataframe()[0]\n",
    "print(\"✅ Loaded COMPAS dataset with shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b214c7a",
   "metadata": {},
   "source": [
    "# ----------------------------\n",
    "# STEP 2: Prepare Data\n",
    "# ----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a612281",
   "metadata": {},
   "outputs": [],
   "source": [
    "protected_attr = 'race'\n",
    "label = 'two_year_recid'\n",
    "y = df[label].values\n",
    "A = df[protected_attr].values\n",
    "X = df.drop(columns=[label]).select_dtypes(include=[np.number])\n",
    "X = X.fillna(0)\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd148e7",
   "metadata": {},
   "source": [
    "# ----------------------------\n",
    "# Helper: Disparate Impact\n",
    "# ----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea83b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disparate_impact(y_true, y_pred, A):\n",
    "    \"\"\"P(Y=1|unpriv)/P(Y=1|priv)\"\"\"\n",
    "    priv = (A == 1)\n",
    "    unpriv = (A == 0)\n",
    "    rate_priv = np.mean(y_pred[priv])\n",
    "    rate_unpriv = np.mean(y_pred[unpriv])\n",
    "    if rate_priv == 0:\n",
    "        return 0\n",
    "    return rate_unpriv / rate_priv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac28751f",
   "metadata": {},
   "source": [
    "# ----------------------------\n",
    "# Helper: Metrics\n",
    "# ----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f053be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred, A, name=\"Model\"):\n",
    "    dp = demographic_parity_difference(y_true, y_pred, sensitive_features=A)\n",
    "    eo = equalized_odds_difference(y_true, y_pred, sensitive_features=A)\n",
    "    di = disparate_impact(y_true, y_pred, A)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"Accuracy: {acc:.3f}, DP Diff: {dp:.3f}, EO Diff: {eo:.3f}, DI: {di:.3f}\")\n",
    "    return {\"Model\": name, \"Accuracy\": acc, \"DP Diff\": dp, \"EO Diff\": eo, \"DI\": di}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cd464a",
   "metadata": {},
   "source": [
    "# ----------------------------\n",
    "# STEP 3: Baseline Logistic Regression\n",
    "# ----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f4f242",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "baseline_results = compute_metrics(y, y_pred, A, \"Baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e99dfe",
   "metadata": {},
   "source": [
    "# ----------------------------\n",
    "# STEP 4: Oversampling\n",
    "# ----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f74f62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.DataFrame(X)\n",
    "df_full[\"y\"] = y\n",
    "df_full[\"A\"] = A\n",
    "\n",
    "minority = df_full[df_full[\"y\"] == 1]\n",
    "majority = df_full[df_full[\"y\"] == 0]\n",
    "minority_oversampled = resample(minority, replace=True,\n",
    "                                n_samples=len(majority),\n",
    "                                random_state=42)\n",
    "df_balanced = pd.concat([majority, minority_oversampled])\n",
    "\n",
    "X_os = df_balanced.drop(columns=[\"y\", \"A\"]).values\n",
    "y_os = df_balanced[\"y\"].values\n",
    "A_os = df_balanced[\"A\"].values\n",
    "\n",
    "model_os = LogisticRegression(max_iter=1000)\n",
    "model_os.fit(X_os, y_os)\n",
    "y_pred_os = model_os.predict(X)\n",
    "oversample_results = compute_metrics(y, y_pred_os, A, \"Oversampling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a3e00f",
   "metadata": {},
   "source": [
    "\n",
    "# ------------------------------\n",
    "# STEP 5: Threshold Optimization\n",
    "# ------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3cb51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = model.predict_proba(X)[:, 1]\n",
    "thresholds = np.linspace(0.1, 0.9, 30)\n",
    "\n",
    "best_threshold = 0.5\n",
    "best_score = -np.inf\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred_t = (y_scores >= t).astype(int)\n",
    "    acc = accuracy_score(y, y_pred_t)\n",
    "    dp = abs(demographic_parity_difference(y, y_pred_t, sensitive_features=A))\n",
    "    eo = abs(equalized_odds_difference(y, y_pred_t, sensitive_features=A))\n",
    "    di = disparate_impact(y, y_pred_t, A)\n",
    "    fairness_penalty = (dp + eo)  # smaller = fairer\n",
    "    score = acc - 0.5 * fairness_penalty  # balance fairness vs accuracy\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_threshold = t\n",
    "\n",
    "print(f\"\\n✅ Optimal threshold for fairness–accuracy tradeoff: {best_threshold:.3f}\")\n",
    "\n",
    "y_pred_th = (y_scores >= best_threshold).astype(int)\n",
    "threshold_results = compute_metrics(y, y_pred_th, A, \"Threshold Optimization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a48657",
   "metadata": {},
   "source": [
    "# ----------------------------\n",
    "# STEP 6: Reweighing\n",
    "# ----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b89a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "rw = Reweighing(unprivileged_groups=[{'race': 0}],\n",
    "                privileged_groups=[{'race': 1}])\n",
    "rw.fit(compas_data)\n",
    "dataset_transf = rw.transform(compas_data)\n",
    "\n",
    "model_rw = LogisticRegression(max_iter=1000)\n",
    "model_rw.fit(X, y, sample_weight=dataset_transf.instance_weights)\n",
    "y_pred_rw = model_rw.predict(X)\n",
    "reweigh_results = compute_metrics(y, y_pred_rw, A, \"Reweighing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53c80c1",
   "metadata": {},
   "source": [
    "# ----------------------------\n",
    "# STEP 7: Multi-Objective Optimization (Threshold Fine-Tuning)\n",
    "# ----------------------------\n",
    "# Combine fairness & accuracy into a single optimization objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd25db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = -np.inf\n",
    "best_threshold_moo = 0.5\n",
    "results_thresholds = []\n",
    "\n",
    "for t in np.linspace(0.1, 0.9, 30):\n",
    "    y_pred_t = (y_scores >= t).astype(int)\n",
    "    acc = accuracy_score(y, y_pred_t)\n",
    "    dp = abs(demographic_parity_difference(y, y_pred_t, sensitive_features=A))\n",
    "    eo = abs(equalized_odds_difference(y, y_pred_t, sensitive_features=A))\n",
    "    fairness = (dp + eo) / 2\n",
    "    score = 0.7 * acc - 0.3 * fairness  # weighted tradeoff\n",
    "    results_thresholds.append([t, acc, dp, eo, fairness, score])\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_threshold_moo = t\n",
    "\n",
    "y_pred_moo = (y_scores >= best_threshold_moo).astype(int)\n",
    "moo_results = compute_metrics(y, y_pred_moo, A, \"Multi-Objective Opt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4e03b1",
   "metadata": {},
   "source": [
    "# ----------------------------\n",
    "# STEP 8: Visualization\n",
    "# ----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28b4449",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame([\n",
    "    baseline_results,\n",
    "    oversample_results,\n",
    "    threshold_results,\n",
    "    reweigh_results,\n",
    "    moo_results\n",
    "])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(results[\"Model\"], results[\"Accuracy\"], color=\"cornflowerblue\")\n",
    "plt.title(\"Accuracy Comparison\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xticks(rotation=15)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "width = 0.25\n",
    "x = np.arange(len(results))\n",
    "plt.bar(x - width, results[\"DP Diff\"], width, label=\"DP Diff\")\n",
    "plt.bar(x, results[\"EO Diff\"], width, label=\"EO Diff\")\n",
    "plt.bar(x + width, results[\"DI\"], width, label=\"DI\")\n",
    "plt.xticks(x, results[\"Model\"], rotation=15)\n",
    "plt.title(\"Fairness Metrics Comparison\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ Pipeline completed with Disparate Impact & Multi-Objective Optimization.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
